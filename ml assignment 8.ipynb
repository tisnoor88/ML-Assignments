{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyOjDuDue1pNo66gRjqGUB0p"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"eBGVjC3TAQF9","executionInfo":{"status":"ok","timestamp":1764275433009,"user_tz":-330,"elapsed":112,"user":{"displayName":"TISNOOR KAUR","userId":"01945709924630918284"}},"outputId":"57a7bdb0-65ae-402a-a53e-41f66df1ff7c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Train shape: (120, 4) Test shape: (30, 4)\n","--------------------------------------------------\n","=== Kernel: LINEAR ===\n","Accuracy : 1.0000\n","Precision: 1.0000\n","Recall   : 1.0000\n","F1-Score : 1.0000\n","Confusion Matrix:\n","[[10  0  0]\n"," [ 0 10  0]\n"," [ 0  0 10]]\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        10\n","  versicolor       1.00      1.00      1.00        10\n","   virginica       1.00      1.00      1.00        10\n","\n","    accuracy                           1.00        30\n","   macro avg       1.00      1.00      1.00        30\n","weighted avg       1.00      1.00      1.00        30\n","\n","--------------------------------------------------\n","=== Kernel: POLY ===\n","Accuracy : 0.9667\n","Precision: 0.9697\n","Recall   : 0.9667\n","F1-Score : 0.9666\n","Confusion Matrix:\n","[[10  0  0]\n"," [ 0  9  1]\n"," [ 0  0 10]]\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        10\n","  versicolor       1.00      0.90      0.95        10\n","   virginica       0.91      1.00      0.95        10\n","\n","    accuracy                           0.97        30\n","   macro avg       0.97      0.97      0.97        30\n","weighted avg       0.97      0.97      0.97        30\n","\n","--------------------------------------------------\n","=== Kernel: RBF ===\n","Accuracy : 0.9667\n","Precision: 0.9697\n","Recall   : 0.9667\n","F1-Score : 0.9666\n","Confusion Matrix:\n","[[10  0  0]\n"," [ 0  9  1]\n"," [ 0  0 10]]\n","\n","Classification Report:\n","              precision    recall  f1-score   support\n","\n","      setosa       1.00      1.00      1.00        10\n","  versicolor       1.00      0.90      0.95        10\n","   virginica       0.91      1.00      0.95        10\n","\n","    accuracy                           0.97        30\n","   macro avg       0.97      0.97      0.97        30\n","weighted avg       0.97      0.97      0.97        30\n","\n","--------------------------------------------------\n","Best Kernel based on Accuracy: LINEAR\n","Metrics: {'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'F1-Score': 1.0}\n"]}],"source":["from sklearn.datasets import load_iris\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.metrics import (\n","    accuracy_score,\n","    precision_score,\n","    recall_score,\n","    f1_score,\n","    confusion_matrix,\n","    classification_report\n",")\n","import numpy as np\n","\n","# a) Load the dataset and perform trainâ€“test split (80:20)\n","iris = load_iris()\n","X = iris.data\n","y = iris.target\n","X_train, X_test, y_train, y_test = train_test_split(\n","    X, y,\n","    test_size=0.2,\n","    random_state=42,\n","    stratify=y\n",")\n","\n","print(\"Train shape:\", X_train.shape, \"Test shape:\", X_test.shape)\n","print(\"-\" * 50)\n","\n","# b) Train three different SVM models using kernels: Linear, Polynomial (degree=3), RBF\n","kernels = ['linear', 'poly', 'rbf']\n","models = {}\n","results = {}\n","conf_matrices = {}\n","\n","for kernel in kernels:\n","    if kernel == 'poly':\n","        clf = SVC(kernel='poly', degree=3, random_state=42)\n","    else:\n","        clf = SVC(kernel=kernel, random_state=42)\n","\n","    clf.fit(X_train, y_train)\n","    models[kernel] = clf\n","\n","    # Predictions\n","    y_pred = clf.predict(X_test)\n","\n","    # c) Evaluate each model\n","    acc = accuracy_score(y_test, y_pred)\n","    prec = precision_score(y_test, y_pred, average='weighted')\n","    rec = recall_score(y_test, y_pred, average='weighted')\n","    f1 = f1_score(y_test, y_pred, average='weighted')\n","\n","    results[kernel] = {\n","        \"Accuracy\": acc,\n","        \"Precision\": prec,\n","        \"Recall\": rec,\n","        \"F1-Score\": f1\n","    }\n","\n","    # d) Confusion matrix\n","    cm = confusion_matrix(y_test, y_pred)\n","    conf_matrices[kernel] = cm\n","\n","    # Print results\n","    print(f\"=== Kernel: {kernel.upper()} ===\")\n","    print(f\"Accuracy : {acc:.4f}\")\n","    print(f\"Precision: {prec:.4f}\")\n","    print(f\"Recall   : {rec:.4f}\")\n","    print(f\"F1-Score : {f1:.4f}\")\n","    print(\"Confusion Matrix:\")\n","    print(cm)\n","    print(\"\\nClassification Report:\")\n","    print(classification_report(y_test, y_pred, target_names=iris.target_names))\n","    print(\"-\" * 50)\n","\n","# e) Identify the best kernel\n","best_kernel = max(results, key=lambda k: results[k][\"Accuracy\"])\n","print(\"Best Kernel based on Accuracy:\", best_kernel.upper())\n","print(\"Metrics:\", results[best_kernel])\n"]},{"cell_type":"code","source":["from sklearn.datasets import load_breast_cancer\n","from sklearn.model_selection import train_test_split\n","from sklearn.svm import SVC\n","from sklearn.preprocessing import StandardScaler\n","from sklearn.metrics import accuracy_score\n","\n","# A) Load Breast Cancer dataset\n","cancer = load_breast_cancer()\n","X_bc = cancer.data\n","y_bc = cancer.target\n","\n","# Train-test split (80-20)\n","X_train_bc, X_test_bc, y_train_bc, y_test_bc = train_test_split(\n","    X_bc, y_bc,\n","    test_size=0.2,\n","    random_state=42,\n","    stratify=y_bc\n",")\n","\n","print(\"Breast Cancer Train shape:\", X_train_bc.shape, \"Test shape:\", X_test_bc.shape)\n","print(\"-\" * 50)\n","\n","# B1) Train SVM (RBF kernel) WITHOUT feature scaling\n","svm_no_scale = SVC(kernel='rbf', random_state=42)\n","svm_no_scale.fit(X_train_bc, y_train_bc)\n","\n","y_train_pred_no = svm_no_scale.predict(X_train_bc)\n","y_test_pred_no = svm_no_scale.predict(X_test_bc)\n","\n","train_acc_no = accuracy_score(y_train_bc, y_train_pred_no)\n","test_acc_no = accuracy_score(y_test_bc, y_test_pred_no)\n","\n","print(\"=== SVM with RBF kernel WITHOUT Scaling ===\")\n","print(f\"Training Accuracy: {train_acc_no:.4f}\")\n","print(f\"Testing Accuracy : {test_acc_no:.4f}\")\n","print(\"-\" * 50)\n","\n","# B2) Train SVM (RBF kernel) WITH feature scaling (StandardScaler)\n","scaler = StandardScaler()\n","\n","X_train_bc_scaled = scaler.fit_transform(X_train_bc)\n","X_test_bc_scaled = scaler.transform(X_test_bc)\n","\n","svm_scaled = SVC(kernel='rbf', random_state=42)\n","svm_scaled.fit(X_train_bc_scaled, y_train_bc)\n","\n","y_train_pred_scaled = svm_scaled.predict(X_train_bc_scaled)\n","y_test_pred_scaled = svm_scaled.predict(X_test_bc_scaled)\n","\n","train_acc_scaled = accuracy_score(y_train_bc, y_train_pred_scaled)\n","test_acc_scaled = accuracy_score(y_test_bc, y_test_pred_scaled)\n","\n","print(\"=== SVM with RBF kernel WITH Scaling (StandardScaler) ===\")\n","print(f\"Training Accuracy: {train_acc_scaled:.4f}\")\n","print(f\"Testing Accuracy : {test_acc_scaled:.4f}\")\n","print(\"-\" * 50)\n","\n","# C) Simple comparison print\n","print(\" COMPARISON: Effect of Feature Scaling\")\n","print(f\"Without Scaling - Train Acc: {train_acc_no:.4f}, Test Acc: {test_acc_no:.4f}\")\n","print(f\"With Scaling    - Train Acc: {train_acc_scaled:.4f}, Test Acc: {test_acc_scaled:.4f}\")\n","\n","if test_acc_scaled > test_acc_no:\n","    print(\"\\nConclusion: Feature scaling improved SVM performance on the Breast Cancer dataset.\")\n","else:\n","    print(\"\\nConclusion: Feature scaling did not significantly improve performance in this run (but is generally recommended for SVM).\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"jbFE2udCAriq","executionInfo":{"status":"ok","timestamp":1764275482860,"user_tz":-330,"elapsed":75,"user":{"displayName":"TISNOOR KAUR","userId":"01945709924630918284"}},"outputId":"132052ef-d6d6-4d24-a834-4f5fa6cf5361"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Breast Cancer Train shape: (455, 30) Test shape: (114, 30)\n","--------------------------------------------------\n","=== SVM with RBF kernel WITHOUT Scaling ===\n","Training Accuracy: 0.9187\n","Testing Accuracy : 0.9298\n","--------------------------------------------------\n","=== SVM with RBF kernel WITH Scaling (StandardScaler) ===\n","Training Accuracy: 0.9824\n","Testing Accuracy : 0.9825\n","--------------------------------------------------\n"," COMPARISON: Effect of Feature Scaling\n","Without Scaling - Train Acc: 0.9187, Test Acc: 0.9298\n","With Scaling    - Train Acc: 0.9824, Test Acc: 0.9825\n","\n","Conclusion: Feature scaling improved SVM performance on the Breast Cancer dataset.\n"]}]}]}